{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from numpy.random import randint\n",
    "import random\n",
    "import itertools \n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from vf_portalytics.model import PredictionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(random_state, n_informative, collumn_names, **kwargs):\n",
    "    x, y = make_regression(\n",
    "        \n",
    "        n_samples=1000, \n",
    "        n_features=5,\n",
    "        noise=0 if random_state == 1 else 10,\n",
    "        bias=10 if random_state == 1 else 1000,\n",
    "        n_informative=min(n_informative, 5), \n",
    "        random_state=random_state\n",
    "    )\n",
    "    x = pd.DataFrame(x)\n",
    "    x.columns = [name for name in collumn_names]\n",
    "    x = x.assign(**kwargs)\n",
    "    x['yearweek'] = randint(0, 53, len(x))\n",
    "    # pack_type 0: 'Can', 1: 'Bottle'\n",
    "    x['pack_type'] = random.choices([0, 1], k=len(x))\n",
    "    \n",
    "    return x, pd.Series(y)\n",
    "\n",
    "def make_dict():\n",
    "    \"\"\"Creates a dictionary with keys all the combinations between the weeks of the year and the pack types\"\"\"\n",
    "    all_list = [list(range(53)), [0, 1] ]\n",
    "    keys = list(itertools.product(*all_list))\n",
    "    values = random.choices(np.linspace(-2.5, 2.5, num=500), k=len(keys))\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "collumn_names = ['price', 'promo_week_length', \n",
    "                 'yearweek',  'pack_type', 'vol_per_sku']\n",
    "\n",
    "x1, y1 = make_dataset(1, 5, collumn_names, account_banner='A', product_desc='X')\n",
    "x2, y2 = make_dataset(2, 3, collumn_names, account_banner='B', product_desc='Y')\n",
    "\n",
    "# combine into one dataset\n",
    "total_x = pd.concat([x1, x2], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "total_y = pd.concat([y1, y2], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "# Split into train and test\n",
    "train_index, test_index = train_test_split(total_x.index, random_state=5)\n",
    "train_x, train_y = total_x.loc[train_index, :], total_y.loc[train_index]\n",
    "test_x, test_y = total_x.loc[test_index, :], total_y.loc[test_index]\n",
    "\n",
    "# create dictionary \"predicted_market_volumes\" - \"lookup_dict\"\n",
    "lookup_dict = make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "\n",
    "class FeatureSubsetTransform(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, group_cols=None, transformer=None):\n",
    "        \"\"\"Build a feature tranformer\"\"\"\n",
    "        self.transformer = transformer\n",
    "        self.group_cols = group_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Drop the columns that are being used to group the data and fit the transformer\"\"\"\n",
    "        x_in = X.drop([n for n in self.group_cols], axis=1)\n",
    "        self.transformer = self.transformer.fit(X=x_in)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x_in = X.drop([n for n in self.group_cols], axis=1)\n",
    "        # transform the data\n",
    "        transformed_x = self.transformer.transform(X=x_in)\n",
    "        # convert data into initial format\n",
    "        transformed_x = pd.DataFrame(data=transformed_x, index=x_in.index,\n",
    "                                     columns=self.transformer.get_feature_names(x_in.columns))\n",
    "        transformed_x[list(self.group_cols)] = X[list(self.group_cols)]\n",
    "        return transformed_x\n",
    "\n",
    "\n",
    "class FeatureSubsetModel(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, lookup_dict=None, group_cols=None, sub_models=None):\n",
    "        \"\"\"\n",
    "        Build regression model for subsets of feature rows matching particular combination of feature columns.\n",
    "        \"\"\"\n",
    "        self.lookup_dict = lookup_dict\n",
    "        self.group_cols = group_cols\n",
    "        self.sub_models = sub_models\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Partition the training data, X, into groups for each unique combination of values in\n",
    "        ``self.group_cols`` columns. For each group, train the appropriate model specified in\n",
    "        ``self.sub_models``.\n",
    "        \"\"\"\n",
    "        X['predicted_market_volume'] = itemgetter(*zip(X['yearweek'], \n",
    "                                                       X['pack_type']))(self.lookup_dict)\n",
    "        groups = X.groupby(by=list(self.group_cols))\n",
    "        \n",
    "        for gp_key, x_group in groups:\n",
    "            # Find the sub-model for this group key\n",
    "            gp_model = self.sub_models[gp_key]\n",
    "\n",
    "            # Drop the feature values for the group columns, since these are same for all rows\n",
    "            # and so don't contribute anything into the prediction.\n",
    "            x_in = x_group.drop([n for n in self.group_cols], axis=1)\n",
    "            y_in = y.loc[x_in.index]\n",
    "\n",
    "            # Fit the submodel with subset of rows\n",
    "            gp_model = gp_model.fit(X=x_in.values, y=y_in.values)\n",
    "            self.sub_models[gp_key] = gp_model\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Same as ``self.fit()``, but call the ``predict()`` method for each submodel and return the results.\n",
    "        \"\"\"\n",
    "        X['predicted_market_volume'] = itemgetter(*zip(X['yearweek'], \n",
    "                                                       X['pack_type']))(self.lookup_dict)\n",
    "        groups = X.groupby(by=list(self.group_cols))\n",
    "        results = []\n",
    "\n",
    "        for gp_key, x_group in groups:\n",
    "            gp_model = self.sub_models[gp_key]\n",
    "            x_in = x_group.drop([n for n in self.group_cols], axis=1)\n",
    "            \n",
    "            predicted_market_share = gp_model.predict(X=x_in.values)\n",
    "            predicted_market_share = pd.Series(index=x_in.index, data=predicted_market_share)\n",
    "            \n",
    "            result = predicted_market_share.mul(\n",
    "                x_group['predicted_market_volume']).mul(\n",
    "                x_group['promo_week_length']).div(\n",
    "                x_group['vol_per_sku']).clip(lower=0)\n",
    "            \n",
    "            results.append(result)\n",
    "\n",
    "        return pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 FeatureSubsetTransform(group_cols=('account_banner',\n",
       "                                                    'product_desc'),\n",
       "                                        transformer=PolynomialFeatures(degree=2,\n",
       "                                                                       include_bias=True,\n",
       "                                                                       interaction_only=False,\n",
       "                                                                       order='C'))),\n",
       "                ('estimate',\n",
       "                 FeatureSubsetModel(group_cols=('account_banner',\n",
       "                                                'product_desc'),\n",
       "                                    lookup_dict={(0, 0): 0.7464929859719436,\n",
       "                                                 (0, 1): -2.2094188376753507,\n",
       "                                                 (1, 0): -...\n",
       "                                                                             fit_intercept=True,\n",
       "                                                                             n_jobs=None,\n",
       "                                                                             normalize=False),\n",
       "                                                ('B', 'Y'): DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                  criterion='mse',\n",
       "                                                                                  max_depth=None,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  max_leaf_nodes=None,\n",
       "                                                                                  min_impurity_decrease=0.0,\n",
       "                                                                                  min_impurity_split=None,\n",
       "                                                                                  min_samples_leaf=1,\n",
       "                                                                                  min_samples_split=2,\n",
       "                                                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                                                  presort='deprecated',\n",
       "                                                                                  random_state=None,\n",
       "                                                                                  splitter='best')}))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline and perform cross validation using both meth\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "subset_cols = ('account_banner', 'product_desc')\n",
    "sub_models = {\n",
    "    ('A', 'X'): LinearRegression(),\n",
    "    ('B', 'Y'): DecisionTreeRegressor(),\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([  \n",
    "  ('transform', FeatureSubsetTransform(group_cols=subset_cols, transformer=PolynomialFeatures(2))),\n",
    "  ('estimate', FeatureSubsetModel(lookup_dict=lookup_dict, group_cols=subset_cols, sub_models=sub_models))\n",
    "])\n",
    "\n",
    "pipeline.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
